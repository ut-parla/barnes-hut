[general]
# parla, sequential, singlegpu, multigpu, parlamgpu
implementation = parlamgpu

sample_check_size = 10
#if skip_timestep, don't run more than one round, since
#timestep is the step responsible for resetting acc to 0
skip_timestep = True
# Let's run multiple evals on the same
# set of points so we can better measure
# For measuring correctness this value MUST be 1
evaluation_rounds = 1

[quadtree]
particles_per_leaf = 10

[bh]
# 6.673 * math.pow(10, -11)
#grav_constant = 0.0000000001
grav_constant = 1
tick_seconds = 0.005

#
# config belows are implementation specific
[parla]
#grav kernel used will be the sequential,force_calculation
gpus_available = 2

placement_cpu_tasks = 1
placement_gpu_tasks = 0

summarize_cpu_tasks = 2
summarize_gpu_tasks = 0

evaluation_cpu_tasks = 2
evaluation_gpu_tasks = 0

timestep_cpu_tasks = 1
timestep_gpu_tasks = 0

[sequential]
# naive, com_concat, com_concat_dedup
evaluation = com_concat_dedup
# np, numba (np is faster, ignore numba)
grid_placement = np
# guvectorize-cpu, guvectorize-parallel, guvectorize-cuda are broken
# blas is incorrect
# vect is naive baseline
# blas, nop, numba, vect
force_calculation = vect

[singlegpu]
#nothing for now

[multigpu]
ngpus = 1

[pykokkos]
# Cuda, OpenMP
space = Cuda